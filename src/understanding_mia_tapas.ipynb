{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Membership Inference Attacks in TAPAS\n",
    "\n",
    "Exploring the `TAPAS` library with the generator `DP-CGAN`\n",
    "\n",
    "Parameters are chosen to have the notebook run quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np \n",
    "\n",
    "import tapas.datasets\n",
    "import tapas.generators\n",
    "import tapas.threat_models\n",
    "import tapas.attacks\n",
    "import tapas.report\n",
    "\n",
    "from src.helpers import load_generator, load_tabular_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup \n",
    "\n",
    "Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../datasets\"\n",
    "dataset_name = \"Adult\"\n",
    "model_name = \"DPCGANS\"\n",
    "file = f\"Real/real_{dataset_name.lower()}_data.csv\"\n",
    "\n",
    "schema = \"data_schemas/adult.json\"\n",
    "executable_generator = \"src/generator_dp_cgans.py\"\n",
    "\n",
    "\n",
    "# make some restrictions to speed up training\n",
    "N_subsample = 500 \n",
    "# keep only these columns for faster training. Needs to keep columns in the same order\n",
    "# columns_to_keep = [\"age\", \"education\", \"marital-status\", \"occupation\", \"race\", \"sex\", \"label\"]\n",
    "columns_to_keep = [\"age\", \"occupation\", \"race\", \"label\"] # this is much faster than the above\n",
    "# categorical variables with more classes are more difficult to train\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- I created a json file with the data schema in `data_schemas/adult.json`. I am not sure about all the \"countable\" data types, but none of the input data seems continuous/to have decimals. See the tapas documentation: https://privacy-sdg-toolbox.readthedocs.io/en/latest/dataset-schema.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_tabular_dataset(\n",
    "    filename_data=os.path.join(datapath, dataset_name, file),\n",
    "    filename_schema=schema,\n",
    "    N_subsample=N_subsample,\n",
    "    columns_to_keep=columns_to_keep\n",
    ")\n",
    "\n",
    "generator = load_generator(executable_generator, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>60</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>29</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>28</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>White</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15471</th>\n",
       "      <td>25</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13558</th>\n",
       "      <td>51</td>\n",
       "      <td>Sales</td>\n",
       "      <td>White</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       occupation                race  label\n",
       "12491   60  Protective-serv               White  <=50K\n",
       "5068    29    Other-service  Asian-Pac-Islander  <=50K\n",
       "8590    28     Craft-repair               White  <=50K\n",
       "15471   25   Prof-specialty               White  <=50K\n",
       "13558   51            Sales               White   >50K"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the threat model\n",
    "\n",
    "We need to define \n",
    "- The membership of which record to attack\n",
    "- What data does the adversary have? Ie, which and how many records, how many samples do they have access to? \n",
    "- What does the adversary know about the synthetic data generator?\n",
    "\n",
    "This will all be collected in a `threat_model` object. We are then able to use the same threat model for different attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to separate the target record from the original data. We will generate synthetic datasets based on training data that either do or do not include the target record. The attacks then try to distinguish between the two classes of synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>60</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       occupation   race  label\n",
       "12491   60  Protective-serv  White  <=50K"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_ids = [0]\n",
    "target_record = data.get_records(attack_ids)\n",
    "display(target_record.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_records(attack_ids, in_place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the sample sizes \n",
    "- `n_records_training`: number of records from the true data distribution that the adversary has available \n",
    "- `n_records_synth`: number of records in the generated synthetic data sets \n",
    "- In a real use case, this can be 1000s or many more, depending on the application/scenario we have in mind\n",
    "\n",
    "ExactKnowledge vs AuxiliaryKnowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records_training = 10\n",
    "n_records_synth = 10 \n",
    "\n",
    "# because we will use the ExactKnowledge scenario, we provide the exact data set of the size `n_records_training`. \n",
    "# If we used `AuxiliaryDataKnowledge`, we could specify these things in the definition of the threat model\n",
    "specific_data = data.sample(n_samples=n_records_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify the threat model. We need to specify:\n",
    "1. data knowledge: the attacker knows the data set used to for the generator, but is only unsure about whether the target record was included or not (the two candidate data sets differ by one row). This directly links to the definition of differential privacy. How does this impact a given attack? \n",
    "    - Both from the definition context in the `TargetedMIA` and the class definition of `ExactDataKnowledge`, `generate_datasets` is the main method from the `attacker_knowledge` attribute. The method just returns `num_samples` copies of the training dataset (which excludes the target record)\n",
    "    - the method (`generate_samples??`) then uses those records, and randomly adds the target record to the training data set\n",
    "Alternative: auxiliaryknowledge. in this case, `generate_datasets` is more complicated\n",
    "    - split into aux data and test data -- what are they used for?\n",
    "    - then further split the aux or test data set into subsamples as specified \n",
    "    - note that we cannot reuse the generated synthetic data set when we change the assumption on data knowledge\n",
    "\n",
    "2. black-box knowledge on generator: the attacker can call the generator and create new synthetic datasets from a given input dataset (defined in data knowledge)\n",
    "\n",
    "#### Notes\n",
    "\n",
    "This attacker knowledge is interesting, because its modularity allows us to represent different scenarios of data sharing. (The thought experiment should be that assuming we released a synthetic dataset from a generator, how well do the data protect the privacy of the records in the dataset?)\n",
    "- Example: hospitals 1 and 2 provide their data (different records) to generate a synthetic dataset of cancer patients. hospital 1 knows that their records are used in the dataset. now the tought experiment is: given this knowledge, can someone in hospital 1 infer which patients from hospital 2 were included in the training set? in this scenario, the attacker knowledge is just exactly the data set of patients in hospital 1.\n",
    "- But what can we learn from this? Can we still conclude something about differential privacy with such a setting? \n",
    "\n",
    "\n",
    "Moreover\n",
    "- With a given threat model, we can run various attacks. \n",
    "- And it's possible (somehow, not exactly sure how) to re-use the synthetic datasets across attacks, and perhaps even across target records (open question) to be computationally efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_model = tapas.threat_models.TargetedMIA(\n",
    "    attacker_knowledge_data=tapas.threat_models.ExactDataKnowledge(\n",
    "        specific_data),       \n",
    "    attacker_knowledge_generator=tapas.threat_models.BlackBoxKnowledge(\n",
    "            generator, num_synthetic_records=n_records_synth,\n",
    "        ),\n",
    "    target_record=target_record,\n",
    "    generate_pairs=False, # TODO: what does this do exactly?\n",
    "    replace_target=False # TODO: what does this do exactly?\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>60</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       occupation   race  label\n",
       "12491   60  Protective-serv  White  <=50K"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_record.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>60</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       occupation   race  label\n",
       "12491   60  Protective-serv  White  <=50K"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(threat_model.num_labels)\n",
    "display(threat_model.target_record.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it's noteworthy to track the `_memory` attribute. It is a dictionary with keys `True` and `False`, referring to training yes/no.\n",
    "Currently, the dict is empty; since `memorise_datasets` is true, the dict will be consecutively populated by synthetic datasets generated from the data knowledge in the next few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atk_know_data': <tapas.threat_models.mia.MIALabeller at 0x7fef11a70a60>,\n",
       " 'atk_know_gen': <tapas.threat_models.attacker_knowledge.BlackBoxKnowledge at 0x7fef11a70d00>,\n",
       " 'memorise_datasets': True,\n",
       " 'iterator_tracker': tapas.threat_models.attacker_knowledge.SilentIterator,\n",
       " '_memory': {True: ([], []), False: ([], [])},\n",
       " 'num_labels': 1,\n",
       " 'num_concurrent': 1,\n",
       " 'multiple_label_mode': False,\n",
       " 'target_record': <tapas.datasets.dataset.TabularRecord at 0x7fef11b904f0>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(threat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an attack\n",
    "\n",
    "Now we need to define the exact method the adversary uses to distinguish datasets that were generated with the target record included and not included. Many options are possible, and it is important to provide substantive reasoning why a given attack is not considered or why it is favored, relative to others. This depends also on the specific application and on our level of \"conservatism\" (ie, which criterion to use in the closest distance attack). \n",
    "\n",
    "Let's use the `ClosestDistance` attack with the standard distance (Hamming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = tapas.attacks.ClosestDistanceMIA(criterion=\"accuracy\", label=\"Closest-Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_criterion': 'accuracy',\n",
       " 'positive_label': None,\n",
       " 'negative_label': None,\n",
       " '_threshold': None,\n",
       " 'distance': <tapas.attacks.distances.HammingDistance at 0x7fef1273bb20>,\n",
       " '_label': 'Closest-Distance'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to define a few more parameters\n",
    "\n",
    "What do they mean? (in both cases, 100 seems like a good number for a real check)\n",
    "- `n_training_datasets`: Number of data sets the adversary uses to train the attack\n",
    "- `n_testing_datasets`: Number of data sets to evaluate the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_datasets = 10\n",
    "n_testing_datasets = 12 # to highlight the distinction below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the attack\n",
    "\n",
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/src/generator_dp_cgans.py\", line 57, in <module>\n",
      "    main(n_samples)\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/src/generator_dp_cgans.py\", line 46, in main\n",
      "    syn_data = generate_data(df, n)\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/src/generator_dp_cgans.py\", line 39, in generate_data\n",
      "    model.fit(df)\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/dp_cgans/base.py\", line 143, in fit\n",
      "    self._fit(transformed)\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/dp_cgans/dp_cgan_init.py\", line 59, in _fit\n",
      "    self._model.fit(\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/dp_cgans/synthesizers/dp_cgan.py\", line 509, in fit\n",
      "    pen.backward(retain_graph=True) # https://machinelearningmastery.com/how-to-implement-wasserstein-loss-for-generative-adversarial-networks/ \n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/torch/_tensor.py\", line 488, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/dp_cgans/synthesizers/dp_cgan.py\", line 500, in <lambda>\n",
      "    lambda grad: grad.cuda() + (1 / self._batch_size) * sigma\n",
      "  File \"/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/flavio/repositories/projects/GANS/explore-attacks/src/understanding_mia_tapas.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/flavio/repositories/projects/GANS/explore-attacks/src/understanding_mia_tapas.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m attack\u001b[39m.\u001b[39;49mtrain(threat_model, num_samples\u001b[39m=\u001b[39;49mn_training_datasets) \u001b[39m# that's short, 55.2 seconds with few columns\u001b[39;00m\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/attacks/base_classes.py:193\u001b[0m, in \u001b[0;36mTrainableThresholdAttack.train\u001b[0;34m(self, threat_model, num_samples, **attack_score_kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m# All \"training\" (setting internal variables) finished.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m# If the threshold is not specified, train to get the desired tpr or fpr.\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m synthetic_datasets, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreat_model\u001b[39m.\u001b[39;49mgenerate_training_samples(\n\u001b[1;32m    194\u001b[0m     num_samples\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    196\u001b[0m \u001b[39m# Check that there are only two labels.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m unique_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(labels)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:650\u001b[0m, in \u001b[0;36mLabelInferenceThreatModel.generate_training_samples\u001b[0;34m(self, num_samples, ignore_memory)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_training_samples\u001b[39m(\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m, num_samples: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, ignore_memory: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    638\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\u001b[39mlist\u001b[39m[Dataset], \u001b[39mlist\u001b[39m[\u001b[39mbool\u001b[39m]]:\n\u001b[1;32m    639\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[39m    Generate samples to train an attack.\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39m        Whether to use the memoised datasets, or ignore them.\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_samples(num_samples, \u001b[39mTrue\u001b[39;49;00m, ignore_memory)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:616\u001b[0m, in \u001b[0;36mLabelInferenceThreatModel._generate_samples\u001b[0;34m(self, num_samples, training, ignore_memory)\u001b[0m\n\u001b[1;32m    610\u001b[0m         gen_datasets \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\u001b[39m.\u001b[39mrun_until_complete(\n\u001b[1;32m    611\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_async_generate_data(\n\u001b[1;32m    612\u001b[0m                 training_datasets, training, gen_labels \u001b[39mif\u001b[39;00m use_memory \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    613\u001b[0m             )\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         gen_datasets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sync_generate_data(\n\u001b[1;32m    617\u001b[0m             training_datasets, training, gen_labels \u001b[39mif\u001b[39;49;00m use_memory \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    618\u001b[0m         )\n\u001b[1;32m    620\u001b[0m \u001b[39m# Collate the datasets and labels to return. If memory is used, this\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m# fetches the datasets in memory (which includes the generated datasets).\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m# Otherwise, only use the generated datasets.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m use_memory:\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:541\u001b[0m, in \u001b[0;36mLabelInferenceThreatModel._sync_generate_data\u001b[0;34m(self, training_datasets, training, training_labels)\u001b[0m\n\u001b[1;32m    539\u001b[0m gen_datasets \u001b[39m=\u001b[39m []\n\u001b[1;32m    540\u001b[0m \u001b[39mfor\u001b[39;00m idx, ds \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(training_datasets):\n\u001b[0;32m--> 541\u001b[0m     synthetic_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matk_know_gen\u001b[39m.\u001b[39;49mgenerate(ds, training_mode\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m    542\u001b[0m     gen_datasets\u001b[39m.\u001b[39mappend(synthetic_dataset)\n\u001b[1;32m    543\u001b[0m     \u001b[39mif\u001b[39;00m use_memory:\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:283\u001b[0m, in \u001b[0;36mBlackBoxKnowledge.generate\u001b[0;34m(self, training_dataset, training_mode)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, training_dataset: Dataset, training_mode: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator(training_dataset, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_synthetic_records)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/generators/generator.py:113\u001b[0m, in \u001b[0;36mGeneratorFromExecutable.__call__\u001b[0;34m(self, dataset, num_samples)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, dataset, num_samples):\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(dataset)\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(num_samples)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/generators/generator.py:107\u001b[0m, in \u001b[0;36mGeneratorFromExecutable.generate\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mwrite_to_string(), \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    105\u001b[0m     output \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdecode()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m TabularDataset\u001b[39m.\u001b[39;49mread_from_string(output, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mdescription)\n\u001b[1;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo dataset provided to generator\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/datasets/dataset.py:239\u001b[0m, in \u001b[0;36mTabularDataset.read_from_string\u001b[0;34m(cls, data, description)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_from_string\u001b[39m(\u001b[39mcls\u001b[39m, data, description):\n\u001b[1;32m    228\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m    TabularDataset\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m _parse_csv(io\u001b[39m.\u001b[39;49mStringIO(data), description\u001b[39m.\u001b[39;49mschema, description\u001b[39m.\u001b[39;49mlabel)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/datasets/dataset.py:37\u001b[0m, in \u001b[0;36m_parse_csv\u001b[0;34m(fp, schema, label)\u001b[0m\n\u001b[1;32m     31\u001b[0m dtypes \u001b[39m=\u001b[39m {\n\u001b[1;32m     32\u001b[0m     i: get_dtype(col[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m], col[\u001b[39m\"\u001b[39m\u001b[39mrepresentation\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(schema)\n\u001b[1;32m     33\u001b[0m }\n\u001b[1;32m     35\u001b[0m cnames \u001b[39m=\u001b[39m [col[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m schema]\n\u001b[0;32m---> 37\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(fp, header\u001b[39m=\u001b[39mvalidate_header(fp, cnames), dtype\u001b[39m=\u001b[39mdtypes, index_col\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, names\u001b[39m=\u001b[39mcnames)    \n\u001b[1;32m     39\u001b[0m \u001b[39m## Convert any date or datetime fields to datetime.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m [\n\u001b[1;32m     41\u001b[0m     col[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m schema\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m col[\u001b[39m\"\u001b[39m\u001b[39mrepresentation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m col[\u001b[39m\"\u001b[39m\u001b[39mrepresentation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m ]:\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/datasets/dataset.py:77\u001b[0m, in \u001b[0;36mvalidate_header\u001b[0;34m(fp, cnames)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fp, io\u001b[39m.\u001b[39mStringIO):\n\u001b[1;32m     75\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mStringIO(fp\u001b[39m.\u001b[39mgetvalue())\n\u001b[0;32m---> 77\u001b[0m row0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(fp, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, index_col\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, nrows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(row0\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m))):\n\u001b[1;32m     79\u001b[0m     \u001b[39m# is a potential header row\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m (row0\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m cnames)\u001b[39m.\u001b[39mall(): \n\u001b[1;32m     81\u001b[0m         \u001b[39m# is the same.\u001b[39;00m\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "attack.train(threat_model, num_samples=n_training_datasets) # that's short, 55.2 seconds with few columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect now the threat model\n",
    "- `._memory[True]` now has `n_training_datasets` of datasets, but none in `._memory[False]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atk_know_data': <tapas.threat_models.mia.MIALabeller at 0x7fdf94374490>,\n",
       " 'atk_know_gen': <tapas.threat_models.attacker_knowledge.BlackBoxKnowledge at 0x7fdf94374610>,\n",
       " 'memorise_datasets': True,\n",
       " 'iterator_tracker': tapas.threat_models.attacker_knowledge.SilentIterator,\n",
       " '_memory': {True: ([<tapas.datasets.dataset.TabularDataset at 0x7fdfe83aacd0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfe83aab80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9e80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9ee0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9460>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9520>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5b80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5e80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5550>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5340>],\n",
       "   [True, False, True, False, True, False, False, True, False, False]),\n",
       "  False: ([], [])},\n",
       " 'num_labels': 1,\n",
       " 'num_concurrent': 1,\n",
       " 'multiple_label_mode': False,\n",
       " 'target_record': <tapas.datasets.dataset.TabularRecord at 0x7fdfad873910>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(attack.threat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_summary = threat_model.test(attack, num_samples=n_testing_datasets) # 100 takes 10 minutes. 10 takes 40 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are `n_testing_datasets` datasets in `._memory[False]`. They are generated during testing the attack above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atk_know_data': <tapas.threat_models.mia.MIALabeller at 0x7fdf94374490>,\n",
       " 'atk_know_gen': <tapas.threat_models.attacker_knowledge.BlackBoxKnowledge at 0x7fdf94374610>,\n",
       " 'memorise_datasets': True,\n",
       " 'iterator_tracker': tapas.threat_models.attacker_knowledge.SilentIterator,\n",
       " '_memory': {True: ([<tapas.datasets.dataset.TabularDataset at 0x7fdfe83aacd0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfe83aab80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9e80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9ee0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9460>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf943a9520>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5b80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5e80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5550>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94c5340>],\n",
       "   [True, False, True, False, True, False, False, True, False, False]),\n",
       "  False: ([<tapas.datasets.dataset.TabularDataset at 0x7fdf9438dfd0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdf9438ddc0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94ca910>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94caeb0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94dbac0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94dbdf0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94dbb80>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94db0a0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94db7f0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94deaf0>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94dee20>,\n",
       "    <tapas.datasets.dataset.TabularDataset at 0x7fdfc94dea30>],\n",
       "   [False,\n",
       "    True,\n",
       "    False,\n",
       "    False,\n",
       "    False,\n",
       "    False,\n",
       "    True,\n",
       "    False,\n",
       "    True,\n",
       "    False,\n",
       "    True,\n",
       "    False])},\n",
       " 'num_labels': 1,\n",
       " 'num_concurrent': 1,\n",
       " 'multiple_label_mode': False,\n",
       " 'target_record': <tapas.datasets.dataset.TabularRecord at 0x7fdfad873910>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(attack.threat_model) # so now `._memory[False]` also has `num_samples` datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More notes\n",
    "- When a new attack is run on the same threat model (and `memorise_datasets` is `True`), then any pre-existing training/test data sets are reused for future attacks. \n",
    "- If an attack requires more datasets than stored for either training or testing, the number of missing datasets is generated by again calling the generator\n",
    "- An implication of this is there is a \"convienent parallelism\" across threat models, but not across attacks for the same threat model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the results\n",
    "\n",
    "This is not meaningful with the small samples we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -2., -2., -2., -1., -1., -2., -1., -1., -1., -2.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(attack_summary.scores) # what do the scores mean? try with smaller samples?\n",
    "display(len(attack_summary.scores)) # these are the number of samples in the test()\n",
    "display(attack_summary.labels) # I guess these are the indicators for whether the dataset contains the record or not?\n",
    "\n",
    "attack_summary.predictions # so this explains why the FPR and TPR are 0. How can I change it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = attack_summary.get_metrics() # but then I get again this RuntimeWarning: invalid value encountered in divide\n",
    "#   return np.log(max(np.max(tp / fp), np.max((1 - fp) / (1 - tp)))) -- but the TP/FP below are not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>target_id</th>\n",
       "      <th>generator</th>\n",
       "      <th>attack</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_positive_rate</th>\n",
       "      <th>false_positive_rate</th>\n",
       "      <th>mia_advantage</th>\n",
       "      <th>privacy_gain</th>\n",
       "      <th>auc</th>\n",
       "      <th>effective_epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed dataset (EXACT)</td>\n",
       "      <td>0</td>\n",
       "      <td>src/generator_dp_cgans.py</td>\n",
       "      <td>Closest-Distance</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset target_id                  generator  \\\n",
       "0  Unnamed dataset (EXACT)         0  src/generator_dp_cgans.py   \n",
       "\n",
       "             attack  accuracy  true_positive_rate  false_positive_rate  \\\n",
       "0  Closest-Distance      0.75                 1.0                0.375   \n",
       "\n",
       "   mia_advantage  privacy_gain     auc  effective_epsilon  \n",
       "0          0.625         0.375  0.8125                inf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Open questions \n",
    "- When using auxiliary data knowledge, where/how are exactly are `aux_data` and `test_data` used? I could not immediately see it in the code\n",
    "- How does it work with multiple target records?\n",
    "\n",
    "**Multiple target records**\n",
    "\n",
    "I don't understand how this works. \n",
    "\n",
    "We can pass more than one targets in `target_record`. While the resulting object's target records is always the first record, the `threat_model` object has an attribute `_target_records` that stores all the provided targets. I guess the idea is that we can re-use the same target model on the same target record (with the same synthetic data sets generated?).\n",
    "\n",
    "\n",
    "In other words, all the `_target_records` are excluded from the data set that is passed to the synthetic data generator. For an attack, we then use one of the `_target_records` and add it randomly to some of the training datasets that are used to train the attack. (Recall that training dataset = one synthetic dataset plus, by chance, the target record or not).\n",
    "This is handy because we don't have to call the generator multiple times for using the same threat model for multiple records. But, if my understanding above is correct, this can also bias the generated synthetic data set because all of the target records are excluded from the training data to the generator.\n",
    "    \n",
    "But I am wondering whether is this statistically proper? Ie, could it lead to bias in the sense that depending on which *other* target records $x_1$, $x_2$, ..., the audit results for target record $x_0$ differ when we drop other target records from the training data and when we don't? under which assumptions? under which sample size?\n",
    "\n",
    "The documentation says something about this (it's related to the parameters `replace_target` and `generate_pairs` above, so check those out).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
