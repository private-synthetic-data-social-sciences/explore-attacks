{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some attacks on DP-CGANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "import numpy as np \n",
    "\n",
    "import tapas as tps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../datasets\"\n",
    "dataset_name = \"Adult\"\n",
    "model_name = \"DPCGANS\"\n",
    "file = f\"Real/real_{dataset_name.lower()}_data.csv\"\n",
    "\n",
    "schema = \"data_schemas/adult.json\"\n",
    "executable_generator = \"src/generator_dp_cgans.py\"\n",
    "\n",
    "\n",
    "# make some restrictions to speed up training\n",
    "N_subsample = 500 \n",
    "# keep only these columns for faster training. Needs to keep columns in the same order\n",
    "colums_to_keep = [\"age\", \"education\", \"marital-status\", \"occupation\", \"race\", \"sex\", \"label\"]\n",
    "\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- I created a json file with the data schema in `data_schemas/adult.json`. I am not sure about all the \"countable\" data types, but none of the input data seems continuous/to have decimals. See the tapas documentation: https://privacy-sdg-toolbox.readthedocs.io/en/latest/dataset-schema.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tabular_dataset(filename_data, filename_schema, N_subsample=None, colums_to_keep=None):\n",
    "    \"\"\"Load a tabular dataset for use with TAPAS.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    filename_data: str\n",
    "        Full path to the file to load.\n",
    "    filename_schema: str\n",
    "        Full path to the json file with the data schema.\n",
    "    N_subsample: int, optional\n",
    "        Number of random subsample to draw from the original data set.\n",
    "    columns_to_keep: list, optional\n",
    "        If specified, only work with a dataframe with those columns.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename_data, index_col=0)\n",
    "    df = df.sample(N_subsample)\n",
    "    if colums_to_keep is not None:\n",
    "        df = df.loc[:, colums_to_keep]\n",
    "\n",
    "    with open(filename_schema) as file:\n",
    "        # Load the JSON data into a dictionary\n",
    "        data_schema = json.load(file)\n",
    "\n",
    "    data_schema = [col for col in data_schema if col[\"name\"] in colums_to_keep]\n",
    "    assert len(data_schema) == len(colums_to_keep), \"all columns in the dataframe need to be in the data schema\"\n",
    "\n",
    "    data_description = tps.datasets.DataDescription(schema=data_schema)\n",
    "    data = tps.datasets.TabularDataset(data=df, description=data_description)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_generator(filename_exec, data):\n",
    "    \"\"\"Load the executable generator and fit it to the data\n",
    "    \n",
    "    filename_exec: str\n",
    "        Full path and filename of the executable\n",
    "    data: tapas.TabularDataset\n",
    "        The real data that will be used by the generator to create synthetic data.\n",
    "    \"\"\"\n",
    "\n",
    "    generator = tps.generators.GeneratorFromExecutable(exe=filename_exec)\n",
    "    generator.fit(data)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open questions\n",
    "- how is the data knowledge with `specific_data` related to the data set per se? is it the same? a subset? is the target record included or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_tabular_dataset(\n",
    "    filename_data=os.path.join(datapath, dataset_name, file),\n",
    "    filename_schema=schema,\n",
    "    N_subsample=N_subsample,\n",
    "    colums_to_keep=colums_to_keep\n",
    ")\n",
    "\n",
    "generator = load_generator(executable_generator, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to separate the target record from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_record = data.get_records([attack_id])\n",
    "data.drop_records([attack_id], in_place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.data.shape[0] + 1 == df.shape[0], \"data does not contain 1 record less than original df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_set_size = 199\n",
    "specific_data = data.sample(n_samples=training_data_set_size)\n",
    "synthetic_dataset_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_model = tps.threat_models.TargetedMIA(\n",
    "    attacker_knowledge_data=tps.threat_models.ExactDataKnowledge(\n",
    "        specific_data),       \n",
    "    attacker_knowledge_generator=tps.threat_models.BlackBoxKnowledge(\n",
    "            generator, num_synthetic_records=synthetic_dataset_size,\n",
    "        ),\n",
    "    target_record=target_record,\n",
    "    generate_pairs=False,\n",
    "    replace_target=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = tps.attacks.ClosestDistanceMIA(criterion=\"accuracy\", label=\"Closest-Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_criterion': 'accuracy',\n",
       " 'positive_label': None,\n",
       " 'negative_label': None,\n",
       " '_threshold': None,\n",
       " 'distance': <tapas.attacks.distances.HammingDistance at 0x7f7342d2d3d0>,\n",
       " '_label': 'Closest-Distance'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_training \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m attack\u001b[39m.\u001b[39;49mtrain(threat_model, num_samples\u001b[39m=\u001b[39;49mnum_training)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/attacks/base_classes.py:193\u001b[0m, in \u001b[0;36mTrainableThresholdAttack.train\u001b[0;34m(self, threat_model, num_samples, **attack_score_kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m# All \"training\" (setting internal variables) finished.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m# If the threshold is not specified, train to get the desired tpr or fpr.\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m synthetic_datasets, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreat_model\u001b[39m.\u001b[39;49mgenerate_training_samples(\n\u001b[1;32m    194\u001b[0m     num_samples\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    196\u001b[0m \u001b[39m# Check that there are only two labels.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m unique_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(labels)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:650\u001b[0m, in \u001b[0;36mLabelInferenceThreatModel.generate_training_samples\u001b[0;34m(self, num_samples, ignore_memory)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_training_samples\u001b[39m(\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m, num_samples: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, ignore_memory: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    638\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\u001b[39mlist\u001b[39m[Dataset], \u001b[39mlist\u001b[39m[\u001b[39mbool\u001b[39m]]:\n\u001b[1;32m    639\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[39m    Generate samples to train an attack.\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39m        Whether to use the memoised datasets, or ignore them.\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_samples(num_samples, \u001b[39mTrue\u001b[39;49;00m, ignore_memory)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:616\u001b[0m, in \u001b[0;36mLabelInferenceThreatModel._generate_samples\u001b[0;34m(self, num_samples, training, ignore_memory)\u001b[0m\n\u001b[1;32m    610\u001b[0m         gen_datasets \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\u001b[39m.\u001b[39mrun_until_complete(\n\u001b[1;32m    611\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_async_generate_data(\n\u001b[1;32m    612\u001b[0m                 training_datasets, training, gen_labels \u001b[39mif\u001b[39;00m use_memory \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    613\u001b[0m             )\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         gen_datasets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sync_generate_data(\n\u001b[1;32m    617\u001b[0m             training_datasets, training, gen_labels \u001b[39mif\u001b[39;49;00m use_memory \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    618\u001b[0m         )\n\u001b[1;32m    620\u001b[0m \u001b[39m# Collate the datasets and labels to return. If memory is used, this\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m# fetches the datasets in memory (which includes the generated datasets).\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m# Otherwise, only use the generated datasets.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m use_memory:\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:541\u001b[0m, in \u001b[0;36mLabelInferenceThreatModel._sync_generate_data\u001b[0;34m(self, training_datasets, training, training_labels)\u001b[0m\n\u001b[1;32m    539\u001b[0m gen_datasets \u001b[39m=\u001b[39m []\n\u001b[1;32m    540\u001b[0m \u001b[39mfor\u001b[39;00m idx, ds \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(training_datasets):\n\u001b[0;32m--> 541\u001b[0m     synthetic_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matk_know_gen\u001b[39m.\u001b[39;49mgenerate(ds, training_mode\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m    542\u001b[0m     gen_datasets\u001b[39m.\u001b[39mappend(synthetic_dataset)\n\u001b[1;32m    543\u001b[0m     \u001b[39mif\u001b[39;00m use_memory:\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/threat_models/attacker_knowledge.py:283\u001b[0m, in \u001b[0;36mBlackBoxKnowledge.generate\u001b[0;34m(self, training_dataset, training_mode)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, training_dataset: Dataset, training_mode: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator(training_dataset, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_synthetic_records)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/generators/generator.py:113\u001b[0m, in \u001b[0;36mGeneratorFromExecutable.__call__\u001b[0;34m(self, dataset, num_samples)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, dataset, num_samples):\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(dataset)\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(num_samples)\n",
      "File \u001b[0;32m~/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/generators/generator.py:105\u001b[0m, in \u001b[0;36mGeneratorFromExecutable.generate\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    103\u001b[0m     proc \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPopen([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexe, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m], stdin \u001b[39m=\u001b[39m PIPE, stdout \u001b[39m=\u001b[39m PIPE)\n\u001b[1;32m    104\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mwrite_to_string(), \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     output \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39minput\u001b[39;49m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdecode()\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m TabularDataset\u001b[39m.\u001b[39mread_from_string(output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mdescription)\n\u001b[1;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[1;32m   1135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/subprocess.py:1979\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   1973\u001b[0m                         stdout, stderr,\n\u001b[1;32m   1974\u001b[0m                         skip_check_and_raise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1975\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(  \u001b[39m# Impossible :)\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1977\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfailed to raise TimeoutExpired.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1979\u001b[0m ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m   1980\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   1982\u001b[0m \u001b[39m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m \u001b[39m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_training = 1000\n",
    "attack.train(threat_model, num_samples=num_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_summary = threat_model.test(attack, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.,  -5.,  -6.,  -7., -10.,  -6.,  -9.,  -8.,  -9.,  -8.,  -8.,\n",
       "        -7.,  -7.,  -8.,  -8.,  -6.,  -9.,  -8.,  -7.,  -6.,  -7.,  -8.,\n",
       "        -8.,  -9.,  -8.,  -8.,  -7.,  -6.,  -5.,  -6.,  -8.,  -7., -10.,\n",
       "        -7.,  -7.,  -6.,  -8.,  -9.,  -9.,  -8.,  -7.,  -8.,  -6.,  -8.,\n",
       "       -10.,  -7.,  -8.,  -9.,  -5.,  -8.,  -9.,  -7.,  -7.,  -7.,  -8.,\n",
       "        -8.,  -8.,  -7.,  -8.,  -5.,  -7.,  -8.,  -7.,  -8.,  -8.,  -9.,\n",
       "        -9.,  -8.,  -7.,  -9.,  -7.,  -6.,  -5.,  -6., -10.,  -6.,  -5.,\n",
       "        -5.,  -5.,  -7.,  -9.,  -4.,  -7.,  -8.,  -8.,  -4.,  -7.,  -9.,\n",
       "        -6.,  -8.,  -7.,  -8.,  -7.,  -8., -10.,  -8.,  -7.,  -8.,  -6.,\n",
       "        -8.,  -8.,  -7.,  -7.,  -7.,  -9.,  -6.,  -7.,  -4.,  -8.,  -8.,\n",
       "        -8.,  -9.,  -9.,  -5.,  -8.,  -8.,  -8.,  -9.,  -6.,  -8.,  -9.,\n",
       "        -8.,  -8.,  -6.,  -9.,  -8.,  -7.,  -9.,  -6.,  -6.,  -9.,  -6.,\n",
       "        -8.,  -7.,  -7.,  -8.,  -8.,  -8.,  -7.,  -7.,  -8.,  -7.,  -7.,\n",
       "        -9.,  -8.,  -8.,  -9.,  -8.,  -8.,  -7.,  -7.,  -9.,  -9.,  -8.,\n",
       "        -8.,  -9.,  -9.,  -8.,  -6.,  -8.,  -7.,  -7.,  -7.,  -8.,  -7.,\n",
       "        -6.,  -7.,  -9.,  -9.,  -7., -10.,  -6.,  -7.,  -8.,  -6.,  -8.,\n",
       "        -6.,  -8.,  -7.,  -9.,  -8.,  -8.,  -7.,  -8.,  -8.,  -7.,  -9.,\n",
       "        -7.,  -7.,  -6.,  -9.,  -8.,  -7.,  -9.,  -8.,  -8.,  -7.,  -6.,\n",
       "        -8.,  -6.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(attack_summary.scores) # what do the scores mean? try with smaller samples?\n",
    "display(len(attack_summary.scores)) # these are the number of samples in the test()\n",
    "display(attack_summary.labels) # I guess these are the indicators for whether the dataset contains the record or not?\n",
    "\n",
    "\n",
    "type(attack_summary)\n",
    "attack_summary.predictions # so this explains why the FPR and TPR are 0. How can I change it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why do we get all 0s?\n",
    "- because we do not use the generator properly. -- for this, need to check some functioning code (try one of their examples)\n",
    "- because we are too strict (threshold too high/low) -- but should this threshold not be learned in training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = attack_summary.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>target_id</th>\n",
       "      <th>generator</th>\n",
       "      <th>attack</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_positive_rate</th>\n",
       "      <th>false_positive_rate</th>\n",
       "      <th>mia_advantage</th>\n",
       "      <th>privacy_gain</th>\n",
       "      <th>auc</th>\n",
       "      <th>effective_epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed dataset (EXACT)</td>\n",
       "      <td>0</td>\n",
       "      <td>src/generator_from_dataset.py</td>\n",
       "      <td>Closest-Distance</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>-0.053686</td>\n",
       "      <td>1.053686</td>\n",
       "      <td>0.45623</td>\n",
       "      <td>-0.002478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset target_id                      generator  \\\n",
       "0  Unnamed dataset (EXACT)         0  src/generator_from_dataset.py   \n",
       "\n",
       "             attack  accuracy  true_positive_rate  false_positive_rate  \\\n",
       "0  Closest-Distance     0.475            0.427083             0.480769   \n",
       "\n",
       "   mia_advantage  privacy_gain      auc  effective_epsilon  \n",
       "0      -0.053686      1.053686  0.45623          -0.002478  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- `attack_score` takes the min distance between the target record and all synthetic datasets in the list `datasets`. \n",
    "    - so, I need more than one synthetic datasets as inputs?\n",
    "    - should they stem from the same generator?\n",
    "    - read some paper on these attacks/need to understand the background better\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
