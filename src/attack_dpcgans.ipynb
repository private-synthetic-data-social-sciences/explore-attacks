{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some attacks on DP-CGANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "import numpy as np \n",
    "\n",
    "import tapas.datasets\n",
    "import tapas.generators\n",
    "import tapas.threat_models\n",
    "import tapas.attacks\n",
    "import tapas.report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../datasets\"\n",
    "dataset_name = \"Adult\"\n",
    "model_name = \"DPCGANS\"\n",
    "file = f\"Real/real_{dataset_name.lower()}_data.csv\"\n",
    "\n",
    "schema = \"data_schemas/adult.json\"\n",
    "executable_generator = \"src/generator_dp_cgans.py\"\n",
    "\n",
    "\n",
    "# make some restrictions to speed up training\n",
    "N_subsample = 500 \n",
    "# keep only these columns for faster training. Needs to keep columns in the same order\n",
    "# columns_to_keep = [\"age\", \"education\", \"marital-status\", \"occupation\", \"race\", \"sex\", \"label\"]\n",
    "columns_to_keep = [\"age\", \"occupation\", \"race\", \"label\"]\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- I created a json file with the data schema in `data_schemas/adult.json`. I am not sure about all the \"countable\" data types, but none of the input data seems continuous/to have decimals. See the tapas documentation: https://privacy-sdg-toolbox.readthedocs.io/en/latest/dataset-schema.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tabular_dataset(filename_data, filename_schema, N_subsample=None, columns_to_keep=None):\n",
    "    \"\"\"Load a tabular dataset for use with TAPAS.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    filename_data: str\n",
    "        Full path to the file to load.\n",
    "    filename_schema: str\n",
    "        Full path to the json file with the data schema.\n",
    "    N_subsample: int, optional\n",
    "        Number of random subsample to draw from the original data set.\n",
    "    columns_to_keep: list, optional\n",
    "        If specified, only work with a dataframe with those columns.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename_data, index_col=0)\n",
    "    df = df.sample(N_subsample)\n",
    "    if columns_to_keep is not None:\n",
    "        df = df.loc[:, columns_to_keep]\n",
    "\n",
    "    with open(filename_schema) as file:\n",
    "        # Load the JSON data into a dictionary\n",
    "        data_schema = json.load(file)\n",
    "\n",
    "    data_schema = [col for col in data_schema if col[\"name\"] in columns_to_keep]\n",
    "    assert len(data_schema) == len(columns_to_keep), \"all columns in the dataframe need to be in the data schema\"\n",
    "\n",
    "    data_description = tapas.datasets.DataDescription(schema=data_schema)\n",
    "    data = tapas.datasets.TabularDataset(data=df, description=data_description)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_generator(filename_exec, data):\n",
    "    \"\"\"Load the executable generator and fit it to the data\n",
    "    \n",
    "    filename_exec: str\n",
    "        Full path and filename of the executable\n",
    "    data: tapas.TabularDataset\n",
    "        The real data that will be used by the generator to create synthetic data.\n",
    "    \"\"\"\n",
    "\n",
    "    generator = tapas.generators.GeneratorFromExecutable(exe=filename_exec)\n",
    "    generator.fit(data)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open questions\n",
    "- how is the data knowledge with `specific_data` related to the data set per se? is it the same? a subset? is the target record included or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_tabular_dataset(\n",
    "    filename_data=os.path.join(datapath, dataset_name, file),\n",
    "    filename_schema=schema,\n",
    "    N_subsample=N_subsample,\n",
    "    columns_to_keep=columns_to_keep\n",
    ")\n",
    "\n",
    "generator = load_generator(executable_generator, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to separate the target record from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_record = data.get_records([attack_id])\n",
    "data.drop_records([attack_id], in_place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_set_size = 10\n",
    "specific_data = data.sample(n_samples=training_data_set_size)\n",
    "synthetic_dataset_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_model = tapas.threat_models.TargetedMIA(\n",
    "    attacker_knowledge_data=tapas.threat_models.ExactDataKnowledge(\n",
    "        specific_data),       \n",
    "    attacker_knowledge_generator=tapas.threat_models.BlackBoxKnowledge(\n",
    "            generator, num_synthetic_records=synthetic_dataset_size,\n",
    "        ),\n",
    "    target_record=target_record,\n",
    "    generate_pairs=False,\n",
    "    replace_target=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = tapas.attacks.ClosestDistanceMIA(criterion=\"accuracy\", label=\"Closest-Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_criterion': 'accuracy',\n",
       " 'positive_label': None,\n",
       " 'negative_label': None,\n",
       " '_threshold': None,\n",
       " 'distance': <tapas.attacks.distances.HammingDistance at 0x7fa7b1508d60>,\n",
       " '_label': 'Closest-Distance'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training = 10\n",
    "attack.train(threat_model, num_samples=num_training) # that's short, 55.2 seconds with few columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_summary = threat_model.test(attack, num_samples=10) # 100 takes 10 minutes. 10 takes 40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2., -2., -2., -2., -2., -1., -1., -1., -2., -1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(attack_summary.scores) # what do the scores mean? try with smaller samples?\n",
    "display(len(attack_summary.scores)) # these are the number of samples in the test()\n",
    "display(attack_summary.labels) # I guess these are the indicators for whether the dataset contains the record or not?\n",
    "\n",
    "\n",
    "type(attack_summary)\n",
    "attack_summary.predictions # so this explains why the FPR and TPR are 0. How can I change it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why do we get all 0s?\n",
    "- because we do not use the generator properly. -- for this, need to check some functioning code (try one of their examples)\n",
    "- because we are too strict (threshold too high/low) -- but should this threshold not be learned in training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flavio/repositories/projects/GANS/explore-attacks/.venv/lib/python3.9/site-packages/tapas/report/attack_summary.py:262: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.log(max(np.max(tp / fp), np.max((1 - fp) / (1 - tp))))\n"
     ]
    }
   ],
   "source": [
    "metrics = attack_summary.get_metrics() # but then I get again this RuntimeWarning: invalid value encountered in divide\n",
    "#   return np.log(max(np.max(tp / fp), np.max((1 - fp) / (1 - tp)))) -- but the TP/FP below are not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>target_id</th>\n",
       "      <th>generator</th>\n",
       "      <th>attack</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_positive_rate</th>\n",
       "      <th>false_positive_rate</th>\n",
       "      <th>mia_advantage</th>\n",
       "      <th>privacy_gain</th>\n",
       "      <th>auc</th>\n",
       "      <th>effective_epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed dataset (EXACT)</td>\n",
       "      <td>0</td>\n",
       "      <td>src/generator_dp_cgans.py</td>\n",
       "      <td>Closest-Distance</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.095238</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset target_id                  generator  \\\n",
       "0  Unnamed dataset (EXACT)         0  src/generator_dp_cgans.py   \n",
       "\n",
       "             attack  accuracy  true_positive_rate  false_positive_rate  \\\n",
       "0  Closest-Distance       0.5            0.333333             0.428571   \n",
       "\n",
       "   mia_advantage  privacy_gain       auc  effective_epsilon  \n",
       "0      -0.095238      1.095238  0.452381                0.0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- `attack_score` takes the min distance between the target record and all synthetic datasets in the list `datasets`. \n",
    "    - so, I need more than one synthetic datasets as inputs?\n",
    "    - should they stem from the same generator?\n",
    "    - read some paper on these attacks/need to understand the background better\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
